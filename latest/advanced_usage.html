

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>BotSIM System Design &mdash; BotSIM  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Remediator Dashboard Navigation" href="dashboard.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> BotSIM
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro.html">What is BotSIM?</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro.html#getting-started">Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep-dive</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deep_dive.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep_dive.html#generator">Generator</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep_dive.html#simulator">Simulator</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep_dive.html#remediator">Remediator</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Retrieve Einstein BotBuilder Bot Metadata</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html#streamlit-web-app">Streamlit Web App</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html#command-line-tools">Command Line Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html#id1">Dialog Act Maps Revision Guideline</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">Remediator Dashboard Navigation</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html#apply-intent-model-remediation-suggestions">Apply Intent Model Remediation Suggestions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Usage</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">BotSIM System Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#infrastructure-layer">Infrastructure Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#adaptor-layer">Adaptor Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#application-layer">Application Layer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#extending-botsim-to-new-bot-platforms">Extending BotSIM to New Bot Platforms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#parser">Parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bot-api-client">Bot API Client</a></li>
<li class="toctree-l2"><a class="reference internal" href="#adding-new-rules-to-botsim-policy">Adding New Rules to BotSIM Policy</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#incorporating-advanced-models">Incorporating Advanced Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#natural-language-inference-nli-model-as-botsim-nlu">Natural Language Inference (NLI) Model as BotSIM NLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="#neural-based-nlg-model">Neural-based NLG Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#finetune-t5-paraphrasing-model">Finetune T5 Paraphrasing Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#prepare-paraphrase-pairs">Prepare Paraphrase Pairs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#set-training-parameters">Set Training Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#customize-model-and-trainer">Customize Model and Trainer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#gcp-deployment">GCP Deployment</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">BotSIM</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>BotSIM System Design</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/advanced_usage.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="botsim-system-design">
<h1>BotSIM System Design<a class="headerlink" href="#botsim-system-design" title="Permalink to this heading">¶</a></h1>
<p>The key design principles of BotSIM include modularity, extensibility and usability. These principles allow BotSIM to be adopted both by developers as a framework and bot end-users as  an easy-to-use application.
To achieve these, BotSIM adopts a layered design comprising the infrastructure layer, the adaptor layer and the application layer as shown in the figure below.</p>
<a class="reference internal image-reference" href="_images/BotSIM_design.png"><img alt="_images/BotSIM_design.png" src="_images/BotSIM_design.png" style="width: 550px;" /></a>
<section id="infrastructure-layer">
<h2>Infrastructure Layer<a class="headerlink" href="#infrastructure-layer" title="Permalink to this heading">¶</a></h2>
<p>The infrastructure layer is designed to offer fundamental model support for the framework. BotSIM’s <code class="docutils literal notranslate"><span class="pre">generation-simulation-remediation</span></code> pipeline is powered by the models and components that reside in this layer.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">botsim.models</span></code> contains BotSIM’s  NLU and NLG models. From a dialogue system perspective, BotSIM can be viewed as a counterpart to a chatbot: it needs to “understand” chatbot messages (NLU) and “respond” in natural languages (NLG).
Currently, fuzzy matching-based NLU and template-based NLG models are provided for efficiency reasons. Developers can also incorporate more advanced NLU and NLG models (see the <a class="reference external" href="https://opensource.salesforce.com/botsim//latest/advanced_usage.html">advanced usages</a> section).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">botsim.modules</span></code> consists of the three key  modules to power BotSIM’s “generation-simulation-remediation” pipeline.</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">botsim.modules.generator</span></code>  provides two major functionalities: 1) the <code class="docutils literal notranslate"><span class="pre">parser</span></code> parses the input bot designs in the form of either metadata (Einstein BotBuilder) or API (DialogFlow CX) to infer the dialog-act maps (BotSIM’s NLU); 2) the large pre-trained language model based <code class="docutils literal notranslate"><span class="pre">paraphraser</span></code> generates paraphrases from the input intent utterances. These paraphrases are used as intent queries in the simulation goals to probe bots’ intent models, which allows BotSIM to perform large-scale data-efficient bot evaluation even before bots are deployed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">botsim.modules.simulator</span></code> implements the dialog-act level agenda-based user simulation in <code class="docutils literal notranslate"><span class="pre">abus</span></code>. It also defines a simulation API client interface in <code class="docutils literal notranslate"><span class="pre">simulation_client_base</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">botsim.modules.remediator</span></code> analyzes the simulation dialogs and produces the performance metrics and conversational analytics to support the dashboard visualisation.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="adaptor-layer">
<h2>Adaptor Layer<a class="headerlink" href="#adaptor-layer" title="Permalink to this heading">¶</a></h2>
<p>The adaptor layer is designed for bot developers to extend BotSIM to new bot platforms. To cover new bot platforms, the following two most important platform-specific modules of the layer must be implemented.
Note the implementations of these functions are highly platform-dependent. They require the developers to have access to bot platform, design and API documents to understand how bots are designed and how user inputs are elicited by the bots. There is also need to constantly revisit the implementations to incorporate new features that might be missed in the current implementations.
We have provided some recipes in the <a class="reference external" href="https://opensource.salesforce.com/botsim/latest/advanced_usage.html#extending-botsim-to-new-bot-platforms">advanced usage</a> section.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">parser</span></code> acts as an “adaptor” to unify bot definitions (e.g. dialog flows, intents/tasks) from different platforms to a common representation of dialog act maps.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">simulation_client</span></code> is the other platform-dependent component for BotSIM to exchange conversations  with bots via APIs.
Similar to the <code class="docutils literal notranslate"><span class="pre">parser</span></code>, the client implementation heavily depends on the API designs of underlying bot platforms.</p></li>
</ul>
</section>
<section id="application-layer">
<h2>Application Layer<a class="headerlink" href="#application-layer" title="Permalink to this heading">¶</a></h2>
<p>The application layer is designed to significantly flatten the learning curves of BotSIM for both bot developers/practitioners and end-users.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">botsim.cli</span></code> contains a set of command line tools for practitioners to learn more about the  major BotSIM components. The <code class="docutils literal notranslate"><span class="pre">generation-simulation-evaluation</span></code> pipeline has been split into multiple stages to expose the required inputs and expected outputs for each stage. They serve as basic building blocks for bot practitioners to build their customized pipelines or apply only certain tasks rather than the whole BotSIM pipeline.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">botsim.streamlit_app</span></code> is a multi-page easy-to-use Web app designed for direct application by bot end users such as bot admins without diving into technical details.
The app can be deployed as a docker container to cloud platforms for access to more computation resources. We use Streamlit for the App front-ends. Flask backend APIs are implemented to encapsulate
major BotSIM functionalities. The app is also equipped with a SQL database to store  simulation stages and keep track of simulation performance across multiple platforms.</p></li>
</ul>
</section>
</section>
<section id="extending-botsim-to-new-bot-platforms">
<h1>Extending BotSIM to New Bot Platforms<a class="headerlink" href="#extending-botsim-to-new-bot-platforms" title="Permalink to this heading">¶</a></h1>
<p>Bot developers can extend BotSIM to new platforms by implementing their platform-dependent <code class="docutils literal notranslate"><span class="pre">adaptors</span></code> including parsers and API clients.</p>
<section id="parser">
<h2>Parser<a class="headerlink" href="#parser" title="Permalink to this heading">¶</a></h2>
<p>The parser interface is defined in <code class="docutils literal notranslate"><span class="pre">generator.parser</span></code> and has the following important functions.</p>
<p>1. <code class="docutils literal notranslate"><span class="pre">extract_local_dialog_act_map</span></code> function generates a “local” dialog act map by ignoring incoming and output  transitions.
In other words, the local map only considers the messages/actions explicitly defined within the dialog. These local dialog act maps are modelled as graph nodes during
the subsequent conversation graph modelling. In particular, the messages for the two special dialog acts,
namely “intent_success_message”and “dialog_success_message” are also generated here according to heuristics discussed before.
2. <code class="docutils literal notranslate"><span class="pre">conversation_graph_modelling</span></code> models the entire bot design as a graph. Each individual dialog is represented by its local dialog act maps and included as the graph nodes.
Transitions among dialogs are modelled as the graph edges. The graph modelling is based on the <code class="docutils literal notranslate"><span class="pre">networkx</span></code> package.
There are two outputs from the function: the final dialog act maps and the graph data for conversation path visualisation.
3. <code class="docutils literal notranslate"><span class="pre">parse</span></code> function defines a general parser pipeline  starting from parsed local dialog act maps.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="c1"># extract local dialog act maps which are later modelled as graph nodes</span>
  <span class="n">local_dialog_act_maps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_local_dialog_act_map</span><span class="p">()</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">dialog_act_maps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_graph_visualisation_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conversation_graph_modelling</span><span class="p">(</span><span class="n">local_dialog_act_maps</span><span class="p">)</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">dialog_with_intents_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dialog_act_maps</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">dialog_ontology</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">customer_entities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_ontology</span><span class="p">()</span>
</pre></div>
</div>
</div></blockquote>
<p>These parser functions are highly platform dependent and the implementations are non-trivial. It is recommended to refer to bot platform and design documentation during development.
We provide our parser implementations for the Einstein BotBuilder (<code class="docutils literal notranslate"><span class="pre">platform.botbuilder</span></code>) and Google DialogFlow CX (<code class="docutils literal notranslate"><span class="pre">platform.dialogflow_cx</span></code>) platforms.
The utility functions supporting various parser functions are under  <code class="docutils literal notranslate"><span class="pre">modules.generator.utils.&lt;platform-name&gt;/parser_utilities.py</span></code></p>
<p>Given a new bot platform, developers can follow the following steps for implementing their new platform-specific parsers:</p>
<ol class="arabic simple">
<li><p>Refer to bot plaform or design documents or APIs of the platform to study how bot conversations are designed. Useful information includes</p></li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>How user information is elicited by bots in the bot design data</p></li>
<li><p>Relationship between bot messages and  actions for associating bot messages with dialog actions (request/inform)</p></li>
<li><p>What and how entities are requested in the bot messages. Together with the actions, a dialog act map entry can be inferred from the bot messages (e.g., request_Email)</p></li>
</ul>
</div></blockquote>
<ol class="arabic" start="2">
<li><p>Study the bot dialogs to understand their intents and identify the candidate messages for  “intent_success_messages” and “dialog_success_messages”</p></li>
<li><p>Start by implementing <code class="docutils literal notranslate"><span class="pre">modules.generator.utils.&lt;new-platform-name&gt;/parser_utilities.py</span></code> to parse basic bot design elements to extract only dialog/intent information such as messages, actions, transitions. The main purposes of the utility functions include</p>
<blockquote>
<div><ul class="simple">
<li><p>associate bot messages with  actions, entities or dialog transitions</p></li>
<li><p>infer dialog acts from bot messages.</p></li>
</ul>
</div></blockquote>
<p>These utility functions are subsequently called by the <code class="docutils literal notranslate"><span class="pre">extract_local_dialog_act_map</span></code> function to produce the local dialog act maps. They are also responsible for extracting intent training utterances either from metadata (Einstein Bots) or API (Google DialogFlow CX).</p>
</li>
<li><p>Implement main parser functions to aggregate the dialog act maps and conversation graph modelling.</p></li>
<li><p>Depending on the availability or accessibility of bot design documents, step 3 and 4 may need to be iteracted multiple times.</p></li>
</ol>
</section>
<section id="bot-api-client">
<h2>Bot API Client<a class="headerlink" href="#bot-api-client" title="Permalink to this heading">¶</a></h2>
<p>The client interface is defined in <code class="docutils literal notranslate"><span class="pre">modules.simulator.simulation_client_base</span></code>. The  most important function is <code class="docutils literal notranslate"><span class="pre">perform_batch_simulation</span></code> for performing a batch of simulation
episodes starting from <code class="docutils literal notranslate"><span class="pre">simulation_goals[start_episode]</span></code>.</p>
<p>A code snippet of a dialog loop is given below. Note the functions <code class="docutils literal notranslate"><span class="pre">enqueue_bot_actions_from_bot_messages</span></code>, <code class="docutils literal notranslate"><span class="pre">policy</span></code>, <code class="docutils literal notranslate"><span class="pre">locate_simulation_errors</span></code>, <code class="docutils literal notranslate"><span class="pre">log_episode_simulation_results</span></code> of the
<code class="docutils literal notranslate"><span class="pre">user_simulator</span></code> class are platform-agnostic and can be shared by all bot platforms.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">while</span> <span class="n">episode_index</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">simulation_goals</span><span class="p">):</span>
     <span class="n">user_simulator</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">start_episode</span><span class="p">)</span>
     <span class="n">session_finished</span> <span class="o">=</span> <span class="kc">False</span>
     <span class="c1"># a conversation loop between BotSIM and the bot</span>
     <span class="k">while</span> <span class="ow">not</span> <span class="n">session_finished</span><span class="p">:</span>
         <span class="c1"># The simulator (shared by all platforms) parses a list of consecutive</span>
         <span class="c1"># bot messages into a queue of semantic-level actions. BotSIM subsequently</span>
         <span class="c1"># response to such actions one by one.</span>
         <span class="n">status</span> <span class="o">=</span> <span class="n">user_simulator</span><span class="o">.</span><span class="n">enqueue_bot_actions_from_bot_messages</span><span class="p">(</span>
             <span class="s2">&quot;DialogFlow CX&quot;</span><span class="p">,</span>  <span class="c1"># name of the bot</span>
             <span class="n">bot_messages</span><span class="p">,</span>     <span class="c1"># current bot messages</span>
             <span class="n">bot_action_frame</span><span class="p">,</span> <span class="c1"># current dialog state</span>
             <span class="n">start_episode</span><span class="p">,</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">dialog_logs</span><span class="p">)</span>
         <span class="c1"># Response to all bot_actions one by one</span>
         <span class="k">for</span> <span class="n">bot_action</span> <span class="ow">in</span> <span class="n">user_simulator</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;bot_action_queue&quot;</span><span class="p">]:</span>
             <span class="k">if</span> <span class="n">user_simulator</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;fail&quot;</span><span class="p">:</span>
                 <span class="bp">self</span><span class="o">.</span><span class="n">dialog_logs</span><span class="p">[</span><span class="n">start_episode</span><span class="p">][</span><span class="s2">&quot;chat_log&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bot_messages</span><span class="p">)</span>
                 <span class="n">result</span> <span class="o">=</span> <span class="n">user_simulator</span><span class="o">.</span><span class="n">locate_simulation_errors</span><span class="p">()</span>
                 <span class="n">session_finished</span> <span class="o">=</span> <span class="kc">True</span>
             <span class="k">elif</span> <span class="n">user_simulator</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span><span class="p">:</span>
                 <span class="bp">self</span><span class="o">.</span><span class="n">dialog_logs</span><span class="p">[</span><span class="n">start_episode</span><span class="p">][</span><span class="s2">&quot;chat_log&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bot_messages</span><span class="p">)</span>
                 <span class="n">session_finished</span> <span class="o">=</span> <span class="kc">True</span>

             <span class="k">if</span> <span class="n">session_finished</span><span class="p">:</span>
                 <span class="n">episode_success</span><span class="p">,</span> <span class="n">episode_intent_error</span><span class="p">,</span> <span class="n">episode_ner_error</span><span class="p">,</span> \
                 <span class="n">episode_other_error</span><span class="p">,</span> <span class="n">episode_turns</span> <span class="o">=</span> \
                 <span class="n">user_simulator</span><span class="o">.</span><span class="n">log_episode_simulation_results</span><span class="p">(</span>
                 <span class="n">result</span><span class="p">,</span> <span class="n">start_episode</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dialog_logs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dialog_errors</span><span class="p">)</span>
                 <span class="k">break</span>
             <span class="c1"># apply BotSIM rule-based policy to get natural language BotSIM message</span>
             <span class="n">botsim_action</span><span class="p">,</span> <span class="n">botsim_message</span><span class="p">,</span> <span class="n">botsim_response_slots</span> <span class="o">=</span> \
                 <span class="n">user_simulator</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">bot_action</span><span class="p">)</span>
             <span class="c1"># Send BotSIM message back to bot via API to continue conversation</span>
             <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">botsim_message</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                 <span class="n">text_input</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">TextInput</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">botsim_message</span><span class="p">)</span>
                 <span class="n">query_input</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">QueryInput</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text_input</span><span class="p">,</span> <span class="n">language_code</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">)</span>
                 <span class="k">try</span><span class="p">:</span>
                     <span class="n">request</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">DetectIntentRequest</span><span class="p">(</span><span class="n">session</span><span class="o">=</span><span class="n">session_id</span><span class="p">,</span> <span class="n">query_input</span><span class="o">=</span><span class="n">query_input</span><span class="p">)</span>
                     <span class="n">response</span> <span class="o">=</span> <span class="n">session_client</span><span class="o">.</span><span class="n">detect_intent</span><span class="p">(</span><span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">)</span>
                 <span class="k">except</span> <span class="n">InvalidArgument</span><span class="p">:</span>
                     <span class="k">raise</span>

             <span class="n">new_bot_message</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">txt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
                             <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">query_result</span><span class="o">.</span><span class="n">response_messages</span>
                             <span class="k">for</span> <span class="n">txt</span> <span class="ow">in</span> <span class="n">msg</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">text</span><span class="p">]</span>
             <span class="n">bot_messages</span> <span class="o">=</span> <span class="n">new_bot_message</span>
         <span class="n">episode_index</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</section>
<section id="adding-new-rules-to-botsim-policy">
<h2>Adding New Rules to BotSIM Policy<a class="headerlink" href="#adding-new-rules-to-botsim-policy" title="Permalink to this heading">¶</a></h2>
<p>BotSIM’s rule-based policy is defined in the <code class="docutils literal notranslate"><span class="pre">policy</span></code> functiion of <code class="docutils literal notranslate"><span class="pre">botsim.modules.simulator.user_simulator</span></code>.
The policy takes as input a semantic frame <code class="docutils literal notranslate"><span class="pre">bot_action</span></code> representing the bot dialog actions with the following info:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">action</span></code> denotes the type of action mapped from bot messages via dialog act maps, such as <code class="docutils literal notranslate"><span class="pre">request</span></code>, <code class="docutils literal notranslate"><span class="pre">inform</span></code> etc.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inform_slots</span></code> contains the entitities and values to inform to BotSIM</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">request_slots</span></code> contains the entities requested from BotSIM</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">round</span></code> denotes the dialog turn index of the current bot message</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">message</span></code> is the raw bot message</p></li>
</ul>
<p>The policy updates the dialog states and take the next BotSIM action according to the rule. The BotSIM action is then converted to natural languages by the template NLG and returned.
In principle, a response rule shouold be defined for each bot <code class="docutils literal notranslate"><span class="pre">action</span></code> type, e.g., <code class="docutils literal notranslate"><span class="pre">_response_to_request</span></code>. In other words, if a new  bot dialog act named “&lt;new-dialog-act&gt;”  is included in
the dialog act maps, a corresponding function named   <code class="docutils literal notranslate"><span class="pre">_response_to_&lt;new-dialog-act&gt;</span></code> should be implemented and added to the policy in order for BotSIM to respond to the bot dialog act properly.</p>
</section>
</section>
<section id="incorporating-advanced-models">
<h1>Incorporating Advanced Models<a class="headerlink" href="#incorporating-advanced-models" title="Permalink to this heading">¶</a></h1>
<section id="natural-language-inference-nli-model-as-botsim-nlu">
<h2>Natural Language Inference (NLI) Model as BotSIM NLU<a class="headerlink" href="#natural-language-inference-nli-model-as-botsim-nlu" title="Permalink to this heading">¶</a></h2>
<p>To handle bots that may be powered by a natural language generation model, the lexical-based fuzzy matching NLU is not reliable enough. The limitation can be circumvented by incorporating a semantic-based
NLU. A good candidate is a Natural Language Inference (NLI) model to compute the semantic matching scores of the bot messages with the ones in the dialog act maps.
The NLI model can be added as follows:</p>
<ul class="simple">
<li><p>Create a new subclass of <code class="docutils literal notranslate"><span class="pre">botsim.models.nlu.nlu_model</span></code></p></li>
<li><p>Implement <code class="docutils literal notranslate"><span class="pre">predict(bot_message,</span> <span class="pre">intent_name)</span></code> function to map the <code class="docutils literal notranslate"><span class="pre">bot_message</span></code> to the best dialog act of the <code class="docutils literal notranslate"><span class="pre">intent_name</span></code> dialog</p></li>
<li><p>Switch the <code class="docutils literal notranslate"><span class="pre">nlu_model</span></code> in the user simulator <code class="docutils literal notranslate"><span class="pre">botsim.modules.simulator.abus</span></code> to the new NLU model</p></li>
<li><p>The NLI model scores can also be potentially interpolated with the fuzzy matching score for more robust matching performance</p></li>
</ul>
</section>
<section id="neural-based-nlg-model">
<h2>Neural-based NLG Model<a class="headerlink" href="#neural-based-nlg-model" title="Permalink to this heading">¶</a></h2>
<p>To increase the naturalness and diversity of the template-based responses, a neural-based NLG model may be adopted to “paraphrase” the template messages. One important requirement is that
the NLG model must keep the entity values unchanged in their outputs (i.e., template-guided model).
The model can be incorporated by following the following steps:</p>
<ul class="simple">
<li><p>Create a new NLG module under <code class="docutils literal notranslate"><span class="pre">botsim.models.nlg</span></code></p></li>
<li><p>Implement <code class="docutils literal notranslate"><span class="pre">generate(dialog_state)</span></code> interface to take the semantic representation of dialog state and return a natural language response</p></li>
<li><p>Change the <code class="docutils literal notranslate"><span class="pre">nlg_model</span></code> in the user simulator <code class="docutils literal notranslate"><span class="pre">botsim.modules.simulator.abus</span></code> with the new NLU model</p></li>
</ul>
<p>Alternatively, a retrieval-based NLG model can be used to select appropriate responses from the past chat logs.
Lastly, instead of paraphrasing BotSIM messages, models with natural language prototype/template generation capabilities can be used to produce more templates from the product chat logs. These new
templates can be added directly to the NLG templates.</p>
</section>
</section>
<section id="finetune-t5-paraphrasing-model">
<h1>Finetune T5 Paraphrasing Model<a class="headerlink" href="#finetune-t5-paraphrasing-model" title="Permalink to this heading">¶</a></h1>
<p>To finetune the T5 paraphrasing model on users’ in-domain data, please follow the following steps.</p>
<section id="prepare-paraphrase-pairs">
<h2>Prepare Paraphrase Pairs<a class="headerlink" href="#prepare-paraphrase-pairs" title="Permalink to this heading">¶</a></h2>
<p>The training paraphrase pairs can be created by sampling real user queries with the same intents. The training data should be organized in the following JSON format:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="s2">&quot;&lt;sos_s&gt; &lt;original text 1&gt; &lt;eos_s&gt;&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;paraphrase&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;sos_t&gt; &lt;paraphrased text 1&gt; &lt;eos_t&gt;&quot;</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="s2">&quot;&lt;sos_s&gt; &lt;original text 2&gt; &lt;eos_s&gt;&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;paraphrase&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;sos_t&gt; &lt;paraphrased text 2&gt; &lt;eos_t&gt;&quot;</span>
<span class="w">      </span><span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
<p>To benchmark with the state-of-the-art <a class="reference external" href="https://github.com/tomhosking/hrq-vae">HRQ-VAE</a> model, the dev and test data (in jsonl format) can be directly downloaded from the repo.</p>
</section>
<section id="set-training-parameters">
<h2>Set Training Parameters<a class="headerlink" href="#set-training-parameters" title="Permalink to this heading">¶</a></h2>
<p>The training parameters can be specified in the following <code class="docutils literal notranslate"><span class="pre">train.json</span></code> configuration file.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;pretrained_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;pretrained-model-path&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;dropout&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;number_of_gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;num_train_epochs&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;batch_size_per_gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;test_batch_size_per_gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;max_test_num_batches&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;alpha&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.6</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;test_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;dev.jsonl&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;save_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;chpt-path&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;train_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;train.json&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;optimizer_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;adam_epsilon&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e-8</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;learning_rate&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e-4</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;weight_decay&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;max_grad_norm&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1.0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;warmup_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="customize-model-and-trainer">
<h2>Customize Model and Trainer<a class="headerlink" href="#customize-model-and-trainer" title="Permalink to this heading">¶</a></h2>
<p>To make further changes to the T5 model and trainer, refer to the following files:</p>
<ul class="simple">
<li><p>Model definition: <code class="docutils literal notranslate"><span class="pre">botsim.generator.paraphraser.t5_model</span></code>.</p></li>
<li><p>T5 paraphraser trainer <code class="docutils literal notranslate"><span class="pre">botsim.generator.paraphraser.train.py</span></code>.</p></li>
</ul>
</section>
</section>
<section id="gcp-deployment">
<h1>GCP Deployment<a class="headerlink" href="#gcp-deployment" title="Permalink to this heading">¶</a></h1>
<p>BotSIM Streamlit App can be deployed to GCP for GPU access,  which will greatly accelerate the paraphrasing model inference process.
The script for GCP deployment can be accessed at <code class="docutils literal notranslate"><span class="pre">botsim/deploy/gcp/deploy_gcp_botsim_streamlit.sh</span></code>. The parameters  are as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cluster_name</span></code>: the name of users’ gcp clusters for deployment</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">project_name</span></code>: the project name</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">user_name_space</span></code>: the user name space assigned by the gcp admin</p></li>
</ul>
<p>The yaml configuration file for the deployment is <code class="docutils literal notranslate"><span class="pre">botsim/deploy/gcp/deploy_gpu_streamlit_botsim.yaml</span></code>.  Users need to replace the following placeholders with their own values
before use:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;project-name&gt;</span></code>: same as before</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;deploy-name&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;service-name&gt;</span></code> denote the deployment and service names respectively</p></li>
</ul>
<p>The number of GPUs and CPUs of the container can be set in the <code class="docutils literal notranslate"><span class="pre">resources</span></code> and <code class="docutils literal notranslate"><span class="pre">tolerations</span></code> sections. After successful deployment, the
IP address of the service can be obtained from the <code class="docutils literal notranslate"><span class="pre">external</span> <span class="pre">IP</span></code> field of the result after issuing the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl<span class="w"> </span>-n<span class="w"> </span><span class="nv">$user_name_space</span><span class="w"> </span>get<span class="w"> </span>services
</pre></div>
</div>
<p>The Streamlit App can now be accessed at <code class="docutils literal notranslate"><span class="pre">https://&lt;external-ip&gt;:8501</span></code></p>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="dashboard.html" class="btn btn-neutral float-left" title="Remediator Dashboard Navigation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, salesforce.com inc..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>